{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from denoicer import Denoicer\n",
    "from mecab_wakati import MecabWakati\n",
    "from mbti_util import MbtiUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoicer = Denoicer()\n",
    "mecab_wakati = MecabWakati()\n",
    "mbti_util = MbtiUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>m_type</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>m_type_en</th>\n",
       "      <th>before_or_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>940954542576885760</td>\n",
       "      <td>ä»²ä»‹è€…</td>\n",
       "      <td>1197852103021981696</td>\n",
       "      <td>@yryr_8945 æ‹…å½“åˆ¶ãªã‚“ã ï¼ç¬‘ã“ã®é‡ã§ã“ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã¯æœ¬å½“ã™ã”ã„ğŸ…ãŠç–²ã‚Œæ§˜ã§ã™â˜ºï¸</td>\n",
       "      <td>INFP</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>940954542576885760</td>\n",
       "      <td>ä»²ä»‹è€…</td>\n",
       "      <td>1197318394946543617</td>\n",
       "      <td>@yryr_8945 ãˆã£ï¼è‡ªä½œï¼ã™ã”ã„ï¼</td>\n",
       "      <td>INFP</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>940954542576885760</td>\n",
       "      <td>ä»²ä»‹è€…</td>\n",
       "      <td>1196803484332388352</td>\n",
       "      <td>@stella_kakerun æ˜æ—¥ä¼‘ã¿ã ã‹ã‚‰è¡Œã£ã¦ã¿ã‚‹ğŸ˜­ã‚ã‚ŠãŒã¨ã†ï¼</td>\n",
       "      <td>INFP</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>940954542576885760</td>\n",
       "      <td>ä»²ä»‹è€…</td>\n",
       "      <td>1196785937482575874</td>\n",
       "      <td>ãƒ•ã‚¡ãƒŸãƒè¡Œãæš‡ãªã‹ã£ãŸã‚ˆãƒ¼ğŸ˜­</td>\n",
       "      <td>INFP</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>940954542576885760</td>\n",
       "      <td>ä»²ä»‹è€…</td>\n",
       "      <td>1196389448344207370</td>\n",
       "      <td>ã‚·ãƒ¥ãƒ´ã‚¡ãƒ«ãƒ„ãƒ´ã‚§ãƒ«ãƒ€ãƒ¼ã‚­ãƒ«ã‚·ãƒ¥ãƒˆãƒ«ãƒ†ã‹ãªï¼Ÿ https://t.co/ggxZQ2v6hL</td>\n",
       "      <td>INFP</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             user_id m_type             tweet_id  \\\n",
       "0           0  940954542576885760    ä»²ä»‹è€…  1197852103021981696   \n",
       "1           1  940954542576885760    ä»²ä»‹è€…  1197318394946543617   \n",
       "2           2  940954542576885760    ä»²ä»‹è€…  1196803484332388352   \n",
       "3           3  940954542576885760    ä»²ä»‹è€…  1196785937482575874   \n",
       "4           4  940954542576885760    ä»²ä»‹è€…  1196389448344207370   \n",
       "\n",
       "                                      tweet_text m_type_en before_or_after  \n",
       "0  @yryr_8945 æ‹…å½“åˆ¶ãªã‚“ã ï¼ç¬‘ã“ã®é‡ã§ã“ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã¯æœ¬å½“ã™ã”ã„ğŸ…ãŠç–²ã‚Œæ§˜ã§ã™â˜ºï¸      INFP          before  \n",
       "1                          @yryr_8945 ãˆã£ï¼è‡ªä½œï¼ã™ã”ã„ï¼      INFP          before  \n",
       "2            @stella_kakerun æ˜æ—¥ä¼‘ã¿ã ã‹ã‚‰è¡Œã£ã¦ã¿ã‚‹ğŸ˜­ã‚ã‚ŠãŒã¨ã†ï¼      INFP          before  \n",
       "3                                 ãƒ•ã‚¡ãƒŸãƒè¡Œãæš‡ãªã‹ã£ãŸã‚ˆãƒ¼ğŸ˜­      INFP          before  \n",
       "4  ã‚·ãƒ¥ãƒ´ã‚¡ãƒ«ãƒ„ãƒ´ã‚§ãƒ«ãƒ€ãƒ¼ã‚­ãƒ«ã‚·ãƒ¥ãƒˆãƒ«ãƒ†ã‹ãªï¼Ÿ https://t.co/ggxZQ2v6hL      INFP          before  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_tweets_with_before_after():\n",
    "    path = './database/tweets_with_before_or_after.tsv'\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    # df = df[df['tweet_text'].str.match('(?!@(\\w+) )')]\n",
    "    return df\n",
    "\n",
    "df = read_tweets_with_before_after()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_words(m_type, before_or_after):\n",
    "    df_copy = df[df['m_type_en'] == m_type]\n",
    "    user_ids = list(set(df_copy['user_id']))\n",
    "    words = []\n",
    "    for ids in user_ids:\n",
    "        df_copy = df_copy[df_copy['user_id'] == ids]\n",
    "        df_copy = df_copy[df_copy['before_or_after'] == before_or_after]\n",
    "        user_words = []\n",
    "        for tweet in df_copy['tweet_text']:\n",
    "            user_words += mecab_wakati.wakati_sentence(denoicer.normalize_text(tweet))\n",
    "        words += list(user_words)\n",
    "    return words\n",
    "\n",
    "\n",
    "docs = []\n",
    "for m_type in sorted(mbti_util.m_types):\n",
    "    docs.append(' '.join(create_user_words(\n",
    "        m_type=m_type, before_or_after=\"after\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data1/home/kishima/research-covid-19-mbti/venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.7)  # æ–‡æ›¸å…¨ä½“ã®90%ä»¥ä¸Šã§å‡ºç¾ã™ã‚‹å˜èªã¯ç„¡è¦–ã™ã‚‹\n",
    "X = vectorizer.fit_transform(docs)\n",
    "values = X.toarray()\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for m_type, vec in zip(sorted(mbti_util.m_types), values):\n",
    "    output.append(f'{m_type}\\n')\n",
    "    for w_id, tfidf in sorted(enumerate(vec), key=lambda x: x[1], reverse=True)[:20]:\n",
    "        word = feature_names[w_id]\n",
    "        output.append(f'{word}\\t{tfidf}\\n')\n",
    "\n",
    "with open('result.txt', 'w', encoding='utf-8') as f:\n",
    "    for o in output:\n",
    "        f.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1822412/1217411716.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  tmp = df.query(\n"
     ]
    }
   ],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã‚ã‚‹å˜èªã‚’å«ã‚€ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡ã®è¡Œã‚’æŠœãå‡ºã™ï¼ˆç¾åœ¨ã¯ã€Œç”Ÿãã‚‹ã€ãŒå«ã¾ã‚Œã‚‹è¡Œã‚’æŠ½å‡ºï¼‰\n",
    "# ã‚³ãƒ­ãƒŠç¦å‰å¾Œã‹å¦ã‹ã¨MBTIã®ã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®š\n",
    "before_after = \"after\"\n",
    "m_type = \"ISFP\"\n",
    "with open('result1.txt', 'w', encoding='utf-8') as f:\n",
    "    tmp = df.query(\n",
    "        'tweet_text.str.contains(\"ç”Ÿãã‚‹\")', engine='python')[df['m_type_en'] == m_type][df['before_or_after'] == before_after]\n",
    "    for i, j in zip(tmp['user_id'], tmp['tweet_text']):\n",
    "        f.write(f'{i}\\t{j}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "210b98d706396c77d792f59245ce4968b85b3888226289c4d26021256b3fa3b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
